### Leture 1

​	**样本空间**仅表示某个实验的所有可能结果的集合，**事件**是样本空间的子集。

概率初步定义：$P(A) = 有利结果的数量/分母中可能结果的数量 $，A是一个事件；（前提：假设所有的结果都是一样的，并且结果有限个，即有限的样本空间）；

乘法规则：如果实验1有N1种可能的结果，实验2有N2种可能的结果，······实验r有Nr种可能的结果，那么总的来说，有N1·N2···Nr组合实验的总体可能结果；

采样表：从N个对象中选k次的可能结果

||按顺序|不按顺序|
| ---- | ---- | ---- |
| 放回 | $N^k$ | $C_{N+k-1}^k$ |
|不放回|$N(N-1)\cdot\cdot\cdot(N-k+1)$|$C_N^k$|

### Lecture 2

​	对于从N个对象中选k次的可能结果为$C_{N+k-1}^k$的证明（放回不按顺序）：

假设k=0，此时可能结果为$C_{N-1}^0$，显而易见的结果为0；

假设k=1，此时可能结果为$C_N^1$；

假设N=2，此时可能结果为$C_{k+1}^k=C_{k+1}^1=k+1$，对于此种情况进行进一步证明：

​	假设有2个桶，随机往里面放7个点，即为从2个对象中选7次的可能结果具象化理解；这里我们使用分割法理解，我们想象一共有7-2=8个位置，从这8个位置中任意选7个作为点的位置，剩余一个放一个隔板，把这8个位置分成2部分，理解2个桶；即可能结果共有$C_8^7=C_8^1$；

由此可以推广到更多个对象和更多次选择；

story proof：

$C_n^k = C_n^{n-k+1}$

​	假设有10个人，我们把他们分为人数分别为6和4的两个小组，在这里我们选4个人出来组成一个小组，剩下的6人组成另一个小组；或者选6个人出来组成一个小组，剩下的4人组成另一个小组；这两种选出来的情况是显而易见是一样的。

$nC_{n-1}^{k-1} = kC_n^k$

​	假设一个班级中共n个人，这个班级里需要k个课代表，而班长又必须是课代表中的一员；这里我们也可以有两种选取的方法；一，可以先从n个人中先选出k位课代表，然后从k位课代表中选1位班长，即$kC_n^k$；二，可以直接从n个人中直接选出1个人担任班长和课代表，然后从剩下的n-1个人中选出k-1位课代表，即$nC_{n-1}^{k-1}$；这两种选法出来的可能结果必定为一样的。

$ C_{m+n}^k = \sum_i^k{C_m^iC_n^{k-i}}$

​	从m+n个对象中选k次的可能结果，与从m个中选i次的可能结果然后乘以从n中选k-i次的可能结果易见是相同的；



进一步的定义对于概率：概率空间由两个成分组成，S和P；S是一个样本空间，P是一个接受事件A的函数，一个作为输入的的映射，事件A是样本空间S的子集；P(A)在[0,1]之间；

​	公理1：$P(\varnothing) = 0, p(S) = 1$

​	公理2：$P(A_1\bigcup A_2) = P(A_1) + P(A_2)$；前提A_1和A_2不相交，可以推广到更多个事件；

### Lecture 3

生日问题：k个人中有两个人会是同一天生日的概率？前提只考虑一年365天的情况，且每个人的生日不与其他人的生日有关联。

当k >= 365 的时候，概率为1；

当k <365 的时候

​	我们从它的反面考虑，如果k个人的生日都不为同一天的可能概率为$365\cdot364\cdot\cdot(365-k+1)/365^k$；

​	所以 $1 - 365\cdot364\cdot\cdot(365-k+1)/365^k$ 是至少有两个人的生日为同一天的概率P(A)；

此时可以得到一个与想象中不太一样的结果
$$
P(A) \approx
\begin{cases}
50.7\%   & \text{}k\text{=23}\\
97\%     & \text{}k\text{=50}\\
99.999\% & \text{}n\text{=100}
\end{cases}
$$
虽然当P(A)=50.7%时，k=23，但是此时对于两个人的对数共有$C_{23}^2 = 23*22/2 = 253$ 对，实际上是对这些对人的生日进行比较；

由上一节课的两个公理可以进而推出许多个公理：

​	（1）$P(A^c) = 1 - P(A)$ 这里 $A^c$ 意味着A的补集；

​		可以简单证明：$1=P(S)=P(A^c\bigcup A)=P(A^c)+P(A)$

​	（2）如果 $A\in B$ 那么 $P(A) < P(B)$

​		证明：$B=A\bigcup(B\bigcap A^c) \rightarrow P(B)=P(A)+P(B\bigcap A^c)\geq P(A)$；因为概率处于0~1之间；

​	（3）$P(A\bigcup B) = P(A)+P(B)-P(A\bigcap B)$ 称为包含排除定理

​		证明：
​		$$A\bigcup B=A\bigcup(B\bigcap A^c) \rightarrow P(A\bigcup B)=P(A)+P(B\bigcap A^c)\\我们可以使用假设法假设P(A)+P(B\bigcap A^c)= P(A)+P(B)-P(A\bigcap B)来进一步证明 \\ P(B)=P(A\bigcap B)+P(B\bigcap A^c)=P(B)$$ 

​		证明成功，我们可以通过Venn图的方法简单求证；

​	由第三个公理推出的公理（4）

​	$P(A\bigcup B\bigcup C) = P(A)+P(B)+P(C)-P(A\bigcap B)-P(A\bigcap C)-P(B\bigcap C)+P(A\bigcap B \bigcap C)$

​		也可以通过Venn图的方法来简单理解求证；

​	由此推出的一般公理

​	$P(A_1\bigcup A_2 \cdot\cdot\bigcup A_n)=\sum_{j=1}^nP(A_j) - \sum_{i<j}P(A_i\bigcap A_j) + \sum_{i<j<k}P(A_i\bigcap A_j\bigcap A_k)+\\ \cdots + (-1)^{n+1}P(A_1\bigcap \cdots\bigcap A_n)$

蒙特洛问题（匹配问题）：有n张标为1到n的卡，我们需要从中抽出n张卡来排成长为n的队列，使得 $A_j$ 为队列的序号j和卡上表的数字j事件，卡上的序号和队列的序号相同的概率为？

​	求解：
$$
P(A_j)=\frac{1}{n}=\frac{(n-1)!}{n!}\\
P(A_i\bigcap A_j) = \frac{(n-2)!}{n!} = \frac{1}{n(n-1)} \\
\vdots\\
P(A_1\bigcap \cdots\bigcap A_n) = \frac{(n-k)!}{n!} \\
$$
​	由此可以得到概率如下：
$$
P(A_1\bigcup A_2\bigcup \cdots\bigcup A_n)=C_n^1P(A_j) - C_n^2P(A_j\bigcap A_k) \cdots +(-1)^{n+1}C_n^nP(A_1\bigcap A_2\bigcap \cdots\bigcap A_n) \\
=\frac{1}{1!} - \frac{1}{2!} + \frac{1}{3!} +\cdots+ (-1)^{n+1}\frac{1}{n!}\approx1-\frac{1}{e}
$$

### Lecture 4

独立性的定义：

A和B具有独立性 $P(A\bigcap B) = P(A)P(B)$

A和B和C具有独立性 $P(A\bigcap B) = P(A)P(B) \ \ P(A\bigcap C) = P(A)P(C) \\ P(B\bigcap C) = P(B)P(C) \ \ P(A\bigcap B \bigcap C) = P(A)P(B)P(C)$

由上面可以易见的推出更多有对象时应该满足的条件；

notes：独立性和不相交完全不一样，虽然看起来似乎很相似，但是不相交中事件A和事件B不会同时发生；

一个著名的例子（Newton-Pepys problem）作为条件概率的认识：

​	一个6面的骰子，摇到每面的概率的相同，记事件A为丢6个骰子，至少有1个为6；记事件B为丢12个骰子，至少有2个为6；记事件C为丢18个骰子，至少有3个为6；三个事件最有可能出现？

​		$P(A) = 1 - (\frac{5}{6})^6 \approx $

​		$P(B) = 1 - (\frac{5}{6})^6 - 12(\frac{1}{6})(\frac{5}{6})^5 \approx $

​		$P(C)= 1 - \sum_{k=0}^2C_{18}^k(\frac{1}{6})^k(\frac{5}{6})^{18-k} \approx $

条件概率：

​	$P(A|B) = \frac{P(A\bigcap B)}{P(B)}$ 

​	有助于条件概率理解的例子：一共10块石头，加起来是1；我们随机选取4块作为事件B，随机选2块作为事件A，这里后来选取的2块刚好在之前选的4块之中的概率就为P(A|B)；我的理解，可以把事件B当作为新的样本空间，把$P(A\bigcap B)$理解为新的样本空间中的新的事件；

几个由条件概率推出的定理：

​	$P(A\bigcap B) = P(A|B)P(B) = P(B|A)P(A) = P(B\bigcap A)$

​	$P(A_1\bigcap A_2\bigcap\cdots\bigcap A_n) = P(A_1)P(A_2|A_1)P(A_3|A_1\bigcap A_2)\cdots P(A_n|A_1\cdots A_{n-1})$

​	贝叶斯（bayes）定律：$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$

### Lecture 5

概率是如何考虑不确定性和随机性的？